{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 华为算法精英赛"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据（`user_app_usage.csv` 除外）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_train = pd.read_csv(\"age_train.csv\", names=['uid','age_group'])\n",
    "age_test = pd.read_csv(\"age_test.csv\", names=['uid'])\n",
    "user_basic_info = pd.read_csv(\"user_basic_info.csv\", names=['uid','gender','city','prodName','ramCapacity','ramLeftRation','romCapacity','romLeftRation','color','fontSize','ct','carrier','os'])\n",
    "user_behavior_info = pd.read_csv(\"user_behavior_info.csv\", names=['uid','bootTimes','AFuncTimes','BFuncTimes','CFuncTimes','DFuncTimes','EFuncTimes','FFuncTimes','FFuncSum'])\n",
    "user_app_actived = pd.read_csv(\"user_app_actived.csv\", names=['uid','appId'])\n",
    "app_info = pd.read_csv(\"app_info.csv\", names=['appId', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2id = {}\n",
    "id2class = {}\n",
    "\n",
    "def mergeBasicTables(baseTable):\n",
    "    \n",
    "    resTable = baseTable.merge(user_basic_info, how='left', on='uid', suffixes=('_base0', '_ubaf'))\n",
    "    resTable = resTable.merge(user_behavior_info, how='left', on='uid', suffixes=('_base1', '_ubef'))\n",
    "    \n",
    "    cat_columns = ['city','prodName','color','carrier','os','ct']\n",
    "    for c in cat_columns:\n",
    "        resTable[c] = resTable[c].apply(lambda x: x if type(x)==str else str(x))\n",
    "        \n",
    "        sort_temp = sorted(list(set(resTable[c])))  \n",
    "        class2id[c+'2id'] = dict(zip(sort_temp, range(1, len(sort_temp)+1)))\n",
    "        id2class['id2'+c] = dict(zip(range(1,len(sort_temp)+1), sort_temp))\n",
    "        resTable[c] = resTable[c].apply(lambda x: class2id[c+'2id'][x])\n",
    "        \n",
    "    return resTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_basic = mergeBasicTables(age_train)\n",
    "test_basic = mergeBasicTables(age_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>age_group</th>\n",
       "      <th>gender</th>\n",
       "      <th>city</th>\n",
       "      <th>prodName</th>\n",
       "      <th>ramCapacity</th>\n",
       "      <th>ramLeftRation</th>\n",
       "      <th>romCapacity</th>\n",
       "      <th>romLeftRation</th>\n",
       "      <th>color</th>\n",
       "      <th>fontSize</th>\n",
       "      <th>ct</th>\n",
       "      <th>carrier</th>\n",
       "      <th>os</th>\n",
       "      <th>bootTimes</th>\n",
       "      <th>AFuncTimes</th>\n",
       "      <th>BFuncTimes</th>\n",
       "      <th>CFuncTimes</th>\n",
       "      <th>DFuncTimes</th>\n",
       "      <th>EFuncTimes</th>\n",
       "      <th>FFuncTimes</th>\n",
       "      <th>FFuncSum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>78</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>80</td>\n",
       "      <td>1.15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000011</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000015</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "      <td>78</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>80</td>\n",
       "      <td>1.30</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000019</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>166</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000023</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>164</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>119</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  age_group  gender  city  prodName  ramCapacity  ramLeftRation  \\\n",
       "0  1000001          4       0    51        78          3.0           0.43   \n",
       "1  1000011          3       0    30       138          NaN            NaN   \n",
       "2  1000015          5       1   228        78          3.0           0.34   \n",
       "3  1000019          3       0    57       166          2.0            NaN   \n",
       "4  1000023          2       1   293       164          2.0           0.34   \n",
       "\n",
       "   romCapacity  romLeftRation  color  fontSize  ct  carrier  os  bootTimes  \\\n",
       "0         32.0           0.46     80      1.15   5        1  14        108   \n",
       "1          NaN            NaN     16       NaN   6        1  15          0   \n",
       "2         32.0           0.06     80      1.30   8        2  14         12   \n",
       "3         17.0            NaN    100       NaN   7        3  15          0   \n",
       "4         16.0           0.06    119      1.00   8        2  12          5   \n",
       "\n",
       "   AFuncTimes  BFuncTimes  CFuncTimes  DFuncTimes  EFuncTimes  FFuncTimes  \\\n",
       "0         0.0         0.0        1.00        0.07         0.0         0.0   \n",
       "1         0.0         0.0        0.00        0.00         0.0         0.0   \n",
       "2         0.0         0.0        0.03        0.13         0.0         0.0   \n",
       "3         0.0         0.0        0.00        0.00         0.0         0.0   \n",
       "4         0.0         0.0        0.00        0.13         0.0         0.0   \n",
       "\n",
       "   FFuncSum  \n",
       "0      3319  \n",
       "1       220  \n",
       "2     21881  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_basic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`user_basic_info.csv` 中的 `ramCapacity`，`ramLeftRation`，`romCapacity`，`romLeftRation` 和 `fontSize` 列都包含 NAN 值，采用平均值进行填充 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_basic['ramCapacity'] = train_basic['ramCapacity'].fillna(round(user_basic_info['ramCapacity'].mean()))\n",
    "test_basic['ramCapacity'] = test_basic['ramCapacity'].fillna(round(user_basic_info['ramCapacity'].mean()))\n",
    "\n",
    "train_basic['ramLeftRation'] = train_basic['ramLeftRation'].fillna(round(user_basic_info['ramLeftRation'].mean()))\n",
    "test_basic['ramLeftRation'] = test_basic['ramLeftRation'].fillna(round(user_basic_info['ramLeftRation'].mean(), 2))\n",
    "\n",
    "train_basic['romCapacity'] = train_basic['romCapacity'].fillna(round(user_basic_info['romCapacity'].mean()))\n",
    "test_basic['romCapacity'] = test_basic['romCapacity'].fillna(round(user_basic_info['romCapacity'].mean()))\n",
    "\n",
    "train_basic['romLeftRation'] = train_basic['romLeftRation'].fillna(round(user_basic_info['romLeftRation'].mean(), 2))\n",
    "test_basic['romLeftRation'] = test_basic['romLeftRation'].fillna(round(user_basic_info['romLeftRation'].mean(), 2))\n",
    "\n",
    "train_basic['fontSize'] = train_basic['fontSize'].fillna(round(user_basic_info['fontSize'].mean(), 2))\n",
    "test_basic['fontSize'] = test_basic['fontSize'].fillna(round(user_basic_info['fontSize'].mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_app = train_basic.merge(user_app_actived, how='left', on='uid')[['uid', 'appId']]\n",
    "test_app = test_basic.merge(user_app_actived, how='left', on='uid')[['uid', 'appId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1, max_df=0.7, tokenizer=lambda x:x.split('#'))\n",
    "train_app_counts = vectorizer.fit_transform(train_app['appId'])\n",
    "test_app_counts = vectorizer.transform(test_app['appId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "X_train = sp.hstack((csr_matrix(train_basic.drop(['uid', 'age_group'], axis=1).values), train_app_counts), format='csr')\n",
    "X_test = sp.hstack((csr_matrix(test_basic.drop(['uid'], axis=1).values), test_app_counts), format='csr')\n",
    "y_train = train_basic['age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34839999999999999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "SVM = svm.LinearSVC(C=0.0001)\n",
    "SVM.fit(X_train[:10000], y_train[:10000])\n",
    "SVM_preds = SVM.predict(X_train[-5000:])\n",
    "accuracy_score(SVM_preds, y_train[-5000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.06: 59.219%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = svm.LinearSVC(C=0.06)\n",
    "SVM.fit(train_app_counts, train_basic['age_group'])\n",
    "SVM_preds = SVM.predict(test_app_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id':test_basic['uid'],'label':SVM_preds})\n",
    "df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id':test_basic['uid'],'label':NB_preds})\n",
    "df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36959999999999998"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf_KNN = KNeighborsClassifier(30)\n",
    "clf_KNN.fit(train_app_counts[:10000], y_train[:10000])\n",
    "KNN_preds = clf_KNN.predict(train_app_counts[-5000:])\n",
    "accuracy_score(KNN_preds, y_train[-5000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取处理好的 `basic` 以及 `app` 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_basic_info = pd.read_csv('./data/train_basic_info.csv')\n",
    "test_basic_info = pd.read_csv('./data/test_basic_info.csv')\n",
    "train_app_info = pd.read_csv('./data/train_app_info.csv')\n",
    "test_app_info = pd.read_csv('./data/test_app_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((train_basic_info.drop(['uid', 'age_group'], axis=1).values, train_app_info[['1stCategory', '2ndCategory', '3rdCategory']].values), axis=1)\n",
    "X_test = np.concatenate((test_basic_info.drop(['uid'], axis=1).values, test_app_info[['1stCategory', '2ndCategory', '3rdCategory']].values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_basic_info['age_group'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50160000000000005"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.LinearSVC(C=0.1)\n",
    "SVM.fit(train_app_counts[:10000], y_train[:10000])\n",
    "SVM_preds = SVM.predict(train_app_counts[-5000:])\n",
    "accuracy_score(SVM_preds, y_train[-5000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "\n",
    "        super(MLP, self).__init__()\n",
    "        # define a liner layer\n",
    "        self.hidden = nn.Linear(n_feature, n_hidden)\n",
    "        # define sigmoid activation \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.predict = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # hidden layer\n",
    "        h1 = self.hidden(x)\n",
    "        # activate function\n",
    "        h2 = self.sigmoid(h1)\n",
    "        # output layer\n",
    "        out = self.predict(h2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countVzer = CountVectorizer(min_df=1, max_df=0.7, tokenizer=lambda x: x.split('#'))\n",
    "train_app_counts = countVzer.fit_transform(train_app_info['appId'])\n",
    "test_app_counts = countVzer.transform(test_app_info['appId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold[1]\n",
      "Batch[0] Train loss: 1.8615\tTrain acc: 0.0195\n",
      "Batch[10] Train loss: 1.7259\tTrain acc: 0.3398\n",
      "Batch[20] Train loss: 1.6279\tTrain acc: 0.3789\n",
      "Batch[30] Train loss: 1.3335\tTrain acc: 0.4766\n",
      "Batch[40] Train loss: 1.1965\tTrain acc: 0.5000\n",
      "Batch[50] Train loss: 1.0711\tTrain acc: 0.5312\n",
      "Batch[60] Train loss: 1.0606\tTrain acc: 0.5469\n",
      "Batch[70] Train loss: 1.0578\tTrain acc: 0.5859\n",
      "Batch[80] Train loss: 1.1155\tTrain acc: 0.4844\n",
      "Batch[90] Train loss: 0.9897\tTrain acc: 0.5820\n",
      "Batch[100] Train loss: 1.0166\tTrain acc: 0.5469\n",
      "Batch[110] Train loss: 1.0605\tTrain acc: 0.5586\n",
      "Batch[120] Train loss: 1.1247\tTrain acc: 0.5000\n",
      "Batch[130] Train loss: 1.1033\tTrain acc: 0.5469\n",
      "Batch[140] Train loss: 1.0275\tTrain acc: 0.5820\n",
      "Batch[150] Train loss: 1.0346\tTrain acc: 0.5234\n",
      "Batch[160] Train loss: 1.1717\tTrain acc: 0.5000\n",
      "Batch[170] Train loss: 1.0382\tTrain acc: 0.5625\n",
      "Batch[180] Train loss: 1.1221\tTrain acc: 0.5547\n",
      "Batch[190] Train loss: 0.9984\tTrain acc: 0.5703\n",
      "Batch[200] Train loss: 1.0961\tTrain acc: 0.5391\n",
      "Batch[210] Train loss: 0.9835\tTrain acc: 0.5898\n",
      "Batch[220] Train loss: 0.9013\tTrain acc: 0.6250\n",
      "Batch[230] Train loss: 0.9964\tTrain acc: 0.5391\n",
      "Batch[240] Train loss: 0.9662\tTrain acc: 0.6094\n",
      "Batch[250] Train loss: 1.0516\tTrain acc: 0.5469\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e74d8486c728>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mclf_MLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mbatch_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_app_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mbatch_y_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_MLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# [[1,2],j] or [[1,2],1:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mextracted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mextracted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    510\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m            \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m            indptr, indices, data)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "device = torch.device(\"cuda:1\")\n",
    "lr = 1e-2\n",
    "weight_decay = 1e-5\n",
    "\n",
    "clf_MLP = MLP(train_app_counts[:2000000].shape[1], 1000, 6)\n",
    "clf_MLP.to(device)\n",
    "optimizer = torch.optim.Adam(clf_MLP.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "for f, (train_index, val_index) in enumerate(kf.split(train_app_counts[:2000000])):\n",
    "    print('Fold[{}]'.format(f+1))\n",
    "    for epoch in range(10):\n",
    "        clf_MLP.train()\n",
    "        for i in range(int(len(train_index)/batch_size)):\n",
    "            batch_X_train = Variable(torch.FloatTensor(train_app_counts[:2000000][train_index][i*batch_size:(i+1)*batch_size].toarray())).to(device)\n",
    "            batch_y_train = Variable(torch.LongTensor(y_train[:2000000][train_index][i*batch_size:(i+1)*batch_size])).to(device)\n",
    "            output = clf_MLP(batch_X_train)\n",
    "\n",
    "            loss = loss_fn(output, batch_y_train-1)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_y_preds = torch.max(output, dim=1)[1]\n",
    "            acc = accuracy_score((batch_y_train-1).cpu(), batch_y_preds.cpu())\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print('Batch[{}] Train loss: {:.4f}\\tTrain acc: {:.4f}'.format(i, loss, acc))\n",
    "\n",
    "        clf_MLP.eval()\n",
    "        with torch.no_grad():\n",
    "            output = clf_MLP(torch.FloatTensor(train_app_counts[-10000:].toarray()).to(device))\n",
    "            loss = loss_fn(output, torch.LongTensor(y_train[-10000:]-1).to(device))\n",
    "            MLP_preds = torch.max(output, dim=1)[1]\n",
    "            acc = accuracy_score(torch.LongTensor(y_train[-10000:]-1).cpu(), MLP_preds.cpu())\n",
    "\n",
    "            print('           Test loss: {:.4f}\\tTest acc: {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.37662281\n",
      "Iteration 2, loss = 0.95313958\n",
      "Iteration 3, loss = 0.71360190\n",
      "Iteration 4, loss = 0.49706417\n",
      "Iteration 5, loss = 0.32677944\n",
      "Iteration 6, loss = 0.20624829\n",
      "Iteration 7, loss = 0.13652077\n",
      "Iteration 8, loss = 0.08753950\n",
      "Iteration 9, loss = 0.05881813\n",
      "Iteration 10, loss = 0.04267850\n",
      "Iteration 11, loss = 0.03232963\n",
      "Iteration 12, loss = 0.02556241\n",
      "Iteration 13, loss = 0.02036107\n",
      "Iteration 14, loss = 0.01697590\n",
      "Iteration 15, loss = 0.01396573\n",
      "Iteration 16, loss = 0.01243395\n",
      "Iteration 17, loss = 0.01049332\n",
      "Iteration 18, loss = 0.00919446\n",
      "Iteration 19, loss = 0.00837245\n",
      "Iteration 20, loss = 0.00746220\n",
      "Iteration 21, loss = 0.00665187\n",
      "Iteration 22, loss = 0.00618236\n",
      "Iteration 23, loss = 0.00603475\n",
      "Iteration 24, loss = 0.00580351\n",
      "Iteration 25, loss = 0.00487482\n",
      "Iteration 26, loss = 0.00467258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4768"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf_MLP = MLPClassifier(solver='adam', activation='relu', hidden_layer_sizes=(100, 100), verbose=True)\n",
    "clf_MLP.fit(train_app_counts[:10000], y_train[:10000])\n",
    "MLP_preds = clf_MLP.predict(train_app_counts[-5000:])\n",
    "accuracy_score(MLP_preds, y_train[-5000:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
